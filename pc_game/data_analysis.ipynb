{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "SEED =1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv',index_col=0)\n",
    "train_data, val_data = train_test_split(train_data,test_size=0.2,shuffle=True,random_state=1234)\n",
    "test_data = pd.read_csv('data/test.csv',index_col=0)\n",
    "\n",
    "X_train = train_data.drop(['blueWins'],axis=1)\n",
    "y_train = train_data['blueWins']\n",
    "\n",
    "X_val = val_data.drop(['blueWins'],axis=1)\n",
    "y_val = val_data['blueWins']\n",
    "\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "ss = preprocessing.StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-26 14:54:04,190]\u001b[0m A new study created in memory with name: no-name-6596fded-e5c6-4f0d-93e8-8676c8d30ae0\u001b[0m\n",
      "feature_fraction, val_score: 0.871127:  14%|#4        | 1/7 [00:00<00:04,  1.44it/s]\u001b[32m[I 2023-01-26 14:54:04,889]\u001b[0m Trial 0 finished with value: 0.8711271852988014 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8711271852988014.\u001b[0m\n",
      "feature_fraction, val_score: 0.871127:  29%|##8       | 2/7 [00:01<00:03,  1.33it/s]\u001b[32m[I 2023-01-26 14:54:05,682]\u001b[0m Trial 1 finished with value: 0.8707726425746829 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8711271852988014.\u001b[0m\n",
      "feature_fraction, val_score: 0.871127:  43%|####2     | 3/7 [00:02<00:02,  1.36it/s]\u001b[32m[I 2023-01-26 14:54:06,395]\u001b[0m Trial 2 finished with value: 0.8711271852988014 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8711271852988014.\u001b[0m\n",
      "feature_fraction, val_score: 0.871127:  57%|#####7    | 4/7 [00:02<00:02,  1.44it/s]\u001b[32m[I 2023-01-26 14:54:07,024]\u001b[0m Trial 3 finished with value: 0.8677496780178358 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.8711271852988014.\u001b[0m\n",
      "feature_fraction, val_score: 0.872695:  71%|#######1  | 5/7 [00:03<00:01,  1.46it/s]\u001b[32m[I 2023-01-26 14:54:07,698]\u001b[0m Trial 4 finished with value: 0.8726950840609016 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.8726950840609016.\u001b[0m\n",
      "feature_fraction, val_score: 0.872695:  86%|########5 | 6/7 [00:04<00:00,  1.36it/s]\u001b[32m[I 2023-01-26 14:54:08,532]\u001b[0m Trial 5 finished with value: 0.8680603821831048 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.8726950840609016.\u001b[0m\n",
      "feature_fraction, val_score: 0.872695: 100%|##########| 7/7 [00:04<00:00,  1.44it/s]\u001b[32m[I 2023-01-26 14:54:09,142]\u001b[0m Trial 6 finished with value: 0.8699487411769736 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.8726950840609016.\u001b[0m\n",
      "feature_fraction, val_score: 0.872695: 100%|##########| 7/7 [00:04<00:00,  1.41it/s]\n",
      "num_leaves, val_score: 0.872695:   5%|5         | 1/20 [00:01<00:20,  1.07s/it]\u001b[32m[I 2023-01-26 14:54:10,217]\u001b[0m Trial 7 finished with value: 0.8694043940505105 and parameters: {'num_leaves': 52}. Best is trial 7 with value: 0.8694043940505105.\u001b[0m\n",
      "num_leaves, val_score: 0.872695:  10%|#         | 2/20 [00:02<00:25,  1.44s/it]\u001b[32m[I 2023-01-26 14:54:11,915]\u001b[0m Trial 8 finished with value: 0.8674830087887739 and parameters: {'num_leaves': 78}. Best is trial 7 with value: 0.8694043940505105.\u001b[0m\n",
      "num_leaves, val_score: 0.872695:  15%|#5        | 3/20 [00:03<00:19,  1.12s/it]\u001b[32m[I 2023-01-26 14:54:12,651]\u001b[0m Trial 9 finished with value: 0.8724243952609425 and parameters: {'num_leaves': 30}. Best is trial 9 with value: 0.8724243952609425.\u001b[0m\n",
      "num_leaves, val_score: 0.872695:  20%|##        | 4/20 [00:05<00:24,  1.56s/it]\u001b[32m[I 2023-01-26 14:54:14,885]\u001b[0m Trial 10 finished with value: 0.8648309041287192 and parameters: {'num_leaves': 112}. Best is trial 9 with value: 0.8724243952609425.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  25%|##5       | 5/20 [00:06<00:19,  1.31s/it]\u001b[32m[I 2023-01-26 14:54:15,755]\u001b[0m Trial 11 finished with value: 0.8750391416228993 and parameters: {'num_leaves': 6}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  30%|###       | 6/20 [00:12<00:38,  2.76s/it]\u001b[32m[I 2023-01-26 14:54:21,316]\u001b[0m Trial 12 finished with value: 0.8409117383682183 and parameters: {'num_leaves': 154}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  35%|###5      | 7/20 [00:14<00:35,  2.72s/it]\u001b[32m[I 2023-01-26 14:54:23,957]\u001b[0m Trial 13 finished with value: 0.8541915827168168 and parameters: {'num_leaves': 52}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  40%|####      | 8/20 [00:17<00:33,  2.82s/it]\u001b[32m[I 2023-01-26 14:54:26,983]\u001b[0m Trial 14 finished with value: 0.8512024903641089 and parameters: {'num_leaves': 63}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  45%|####5     | 9/20 [00:21<00:33,  3.09s/it]\u001b[32m[I 2023-01-26 14:54:30,669]\u001b[0m Trial 15 finished with value: 0.8460377713785776 and parameters: {'num_leaves': 83}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875039:  50%|#####     | 10/20 [00:27<00:39,  3.96s/it]\u001b[32m[I 2023-01-26 14:54:36,567]\u001b[0m Trial 16 finished with value: 0.8411037214246952 and parameters: {'num_leaves': 249}. Best is trial 11 with value: 0.8750391416228993.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  55%|#####5    | 11/20 [00:28<00:26,  2.95s/it]\u001b[32m[I 2023-01-26 14:54:37,238]\u001b[0m Trial 17 finished with value: 0.8752981044102395 and parameters: {'num_leaves': 5}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  60%|######    | 12/20 [00:28<00:18,  2.26s/it]\u001b[32m[I 2023-01-26 14:54:37,935]\u001b[0m Trial 18 finished with value: 0.8738967918691969 and parameters: {'num_leaves': 4}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  65%|######5   | 13/20 [00:29<00:12,  1.74s/it]\u001b[32m[I 2023-01-26 14:54:38,462]\u001b[0m Trial 19 finished with value: 0.8560717492151984 and parameters: {'num_leaves': 2}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  70%|#######   | 14/20 [00:35<00:18,  3.11s/it]\u001b[32m[I 2023-01-26 14:54:44,749]\u001b[0m Trial 20 finished with value: 0.8392913214197695 and parameters: {'num_leaves': 185}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  75%|#######5  | 15/20 [00:37<00:13,  2.69s/it]\u001b[32m[I 2023-01-26 14:54:46,467]\u001b[0m Trial 21 finished with value: 0.8625492430543329 and parameters: {'num_leaves': 24}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  80%|########  | 16/20 [00:42<00:13,  3.46s/it]\u001b[32m[I 2023-01-26 14:54:51,724]\u001b[0m Trial 22 finished with value: 0.8402623739658143 and parameters: {'num_leaves': 120}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  85%|########5 | 17/20 [00:48<00:12,  4.26s/it]\u001b[32m[I 2023-01-26 14:54:57,843]\u001b[0m Trial 23 finished with value: 0.8387118055986523 and parameters: {'num_leaves': 197}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  90%|######### | 18/20 [00:53<00:08,  4.34s/it]\u001b[32m[I 2023-01-26 14:55:02,358]\u001b[0m Trial 24 finished with value: 0.8427153329542586 and parameters: {'num_leaves': 96}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298:  95%|#########5| 19/20 [00:55<00:03,  3.62s/it]\u001b[32m[I 2023-01-26 14:55:04,302]\u001b[0m Trial 25 finished with value: 0.8583852052318196 and parameters: {'num_leaves': 33}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298: 100%|##########| 20/20 [01:01<00:00,  4.58s/it]\u001b[32m[I 2023-01-26 14:55:11,112]\u001b[0m Trial 26 finished with value: 0.8387118055986523 and parameters: {'num_leaves': 252}. Best is trial 17 with value: 0.8752981044102395.\u001b[0m\n",
      "num_leaves, val_score: 0.875298: 100%|##########| 20/20 [01:01<00:00,  3.10s/it]\n",
      "bagging, val_score: 0.875298:  10%|#         | 1/10 [00:00<00:06,  1.33it/s]\u001b[32m[I 2023-01-26 14:55:11,865]\u001b[0m Trial 27 finished with value: 0.8731004389696995 and parameters: {'bagging_fraction': 0.5022631188928168, 'bagging_freq': 4}. Best is trial 27 with value: 0.8731004389696995.\u001b[0m\n",
      "bagging, val_score: 0.875298:  20%|##        | 2/10 [00:01<00:06,  1.32it/s]\u001b[32m[I 2023-01-26 14:55:12,626]\u001b[0m Trial 28 finished with value: 0.8743549416290218 and parameters: {'bagging_fraction': 0.5929846485134523, 'bagging_freq': 5}. Best is trial 28 with value: 0.8743549416290218.\u001b[0m\n",
      "bagging, val_score: 0.875298:  30%|###       | 3/10 [00:02<00:05,  1.29it/s]\u001b[32m[I 2023-01-26 14:55:13,426]\u001b[0m Trial 29 finished with value: 0.8740677592173377 and parameters: {'bagging_fraction': 0.6500423945899443, 'bagging_freq': 3}. Best is trial 28 with value: 0.8743549416290218.\u001b[0m\n",
      "bagging, val_score: 0.875298:  40%|####      | 4/10 [00:03<00:04,  1.27it/s]\u001b[32m[I 2023-01-26 14:55:14,232]\u001b[0m Trial 30 finished with value: 0.8746344823844929 and parameters: {'bagging_fraction': 0.5043241598254691, 'bagging_freq': 3}. Best is trial 30 with value: 0.8746344823844929.\u001b[0m\n",
      "bagging, val_score: 0.875767:  50%|#####     | 5/10 [00:03<00:03,  1.37it/s]\u001b[32m[I 2023-01-26 14:55:14,865]\u001b[0m Trial 31 finished with value: 0.8757674744023234 and parameters: {'bagging_fraction': 0.650530255944633, 'bagging_freq': 5}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767:  60%|######    | 6/10 [00:04<00:02,  1.42it/s]\u001b[32m[I 2023-01-26 14:55:15,520]\u001b[0m Trial 32 finished with value: 0.8747518317984344 and parameters: {'bagging_fraction': 0.8784434104870102, 'bagging_freq': 2}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767:  70%|#######   | 7/10 [00:05<00:02,  1.41it/s]\u001b[32m[I 2023-01-26 14:55:16,230]\u001b[0m Trial 33 finished with value: 0.8746159400712099 and parameters: {'bagging_fraction': 0.5744885940022889, 'bagging_freq': 6}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767:  80%|########  | 8/10 [00:05<00:01,  1.47it/s]\u001b[32m[I 2023-01-26 14:55:16,849]\u001b[0m Trial 34 finished with value: 0.8747502603997466 and parameters: {'bagging_fraction': 0.6808284361862651, 'bagging_freq': 4}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767:  90%|######### | 9/10 [00:06<00:00,  1.51it/s]\u001b[32m[I 2023-01-26 14:55:17,472]\u001b[0m Trial 35 finished with value: 0.8742941336181473 and parameters: {'bagging_fraction': 0.789035434178418, 'bagging_freq': 6}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767: 100%|##########| 10/10 [00:06<00:00,  1.53it/s]\u001b[32m[I 2023-01-26 14:55:18,110]\u001b[0m Trial 36 finished with value: 0.8746400066956411 and parameters: {'bagging_fraction': 0.5769625850064397, 'bagging_freq': 6}. Best is trial 31 with value: 0.8757674744023234.\u001b[0m\n",
      "bagging, val_score: 0.875767: 100%|##########| 10/10 [00:06<00:00,  1.43it/s]\n",
      "feature_fraction_stage2, val_score: 0.875767:  17%|#6        | 1/6 [00:00<00:03,  1.64it/s]\u001b[32m[I 2023-01-26 14:55:18,724]\u001b[0m Trial 37 finished with value: 0.8736393324890649 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.8736393324890649.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767:  33%|###3      | 2/6 [00:01<00:02,  1.54it/s]\u001b[32m[I 2023-01-26 14:55:19,402]\u001b[0m Trial 38 finished with value: 0.8757674744023234 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.8757674744023234.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767:  50%|#####     | 3/6 [00:01<00:01,  1.56it/s]\u001b[32m[I 2023-01-26 14:55:20,028]\u001b[0m Trial 39 finished with value: 0.8757674744023234 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 38 with value: 0.8757674744023234.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767:  67%|######6   | 4/6 [00:02<00:01,  1.53it/s]\u001b[32m[I 2023-01-26 14:55:20,706]\u001b[0m Trial 40 finished with value: 0.8757674744023234 and parameters: {'feature_fraction': 0.516}. Best is trial 38 with value: 0.8757674744023234.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767:  83%|########3 | 5/6 [00:03<00:00,  1.57it/s]\u001b[32m[I 2023-01-26 14:55:21,316]\u001b[0m Trial 41 finished with value: 0.8738231272031676 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.8757674744023234.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767: 100%|##########| 6/6 [00:03<00:00,  1.53it/s]\u001b[32m[I 2023-01-26 14:55:21,999]\u001b[0m Trial 42 finished with value: 0.8757674744023234 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.8757674744023234.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.875767: 100%|##########| 6/6 [00:03<00:00,  1.54it/s]\n",
      "regularization_factors, val_score: 0.875767:   5%|5         | 1/20 [00:00<00:12,  1.52it/s]\u001b[32m[I 2023-01-26 14:55:22,660]\u001b[0m Trial 43 finished with value: 0.875510899986816 and parameters: {'lambda_l1': 0.010867367481695962, 'lambda_l2': 3.272661251984487e-08}. Best is trial 43 with value: 0.875510899986816.\u001b[0m\n",
      "regularization_factors, val_score: 0.875767:  10%|#         | 2/20 [00:01<00:11,  1.57it/s]\u001b[32m[I 2023-01-26 14:55:23,279]\u001b[0m Trial 44 finished with value: 0.8754753781893573 and parameters: {'lambda_l1': 0.02347001035975207, 'lambda_l2': 8.860771609077295e-06}. Best is trial 43 with value: 0.875510899986816.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  15%|#5        | 3/20 [00:01<00:10,  1.60it/s]\u001b[32m[I 2023-01-26 14:55:23,892]\u001b[0m Trial 45 finished with value: 0.8763812355245925 and parameters: {'lambda_l1': 0.03588409214548415, 'lambda_l2': 0.023399792144174602}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  20%|##        | 4/20 [00:02<00:10,  1.54it/s]\u001b[32m[I 2023-01-26 14:55:24,578]\u001b[0m Trial 46 finished with value: 0.8702234742856877 and parameters: {'lambda_l1': 9.029324943841608, 'lambda_l2': 5.6502847027659835e-08}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  25%|##5       | 5/20 [00:03<00:09,  1.55it/s]\u001b[32m[I 2023-01-26 14:55:25,211]\u001b[0m Trial 47 finished with value: 0.8760064318545874 and parameters: {'lambda_l1': 3.3788330024687085e-05, 'lambda_l2': 0.5795160119896301}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  30%|###       | 6/20 [00:03<00:09,  1.54it/s]\u001b[32m[I 2023-01-26 14:55:25,875]\u001b[0m Trial 48 finished with value: 0.8746111650078768 and parameters: {'lambda_l1': 2.776106350290606, 'lambda_l2': 0.03766059094631062}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  35%|###5      | 7/20 [00:04<00:08,  1.55it/s]\u001b[32m[I 2023-01-26 14:55:26,503]\u001b[0m Trial 49 finished with value: 0.8757784744522101 and parameters: {'lambda_l1': 6.18743131573665e-08, 'lambda_l2': 0.023242216444915444}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  40%|####      | 8/20 [00:05<00:07,  1.56it/s]\u001b[32m[I 2023-01-26 14:55:27,136]\u001b[0m Trial 50 finished with value: 0.8757673828117729 and parameters: {'lambda_l1': 0.011584692777723529, 'lambda_l2': 5.287228448786829e-06}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  45%|####5     | 9/20 [00:05<00:07,  1.55it/s]\u001b[32m[I 2023-01-26 14:55:27,797]\u001b[0m Trial 51 finished with value: 0.875826343500448 and parameters: {'lambda_l1': 0.00017405528574237212, 'lambda_l2': 0.004013661077643497}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  50%|#####     | 10/20 [00:06<00:06,  1.56it/s]\u001b[32m[I 2023-01-26 14:55:28,425]\u001b[0m Trial 52 finished with value: 0.8754541208467701 and parameters: {'lambda_l1': 0.13483087390167423, 'lambda_l2': 0.705978989064331}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  55%|#####5    | 11/20 [00:07<00:05,  1.57it/s]\u001b[32m[I 2023-01-26 14:55:29,058]\u001b[0m Trial 53 finished with value: 0.8757669844836254 and parameters: {'lambda_l1': 3.03659040779595e-07, 'lambda_l2': 0.00018164266043035944}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  60%|######    | 12/20 [00:07<00:05,  1.57it/s]\u001b[32m[I 2023-01-26 14:55:29,692]\u001b[0m Trial 54 finished with value: 0.8755210645522032 and parameters: {'lambda_l1': 2.8522436048482894e-05, 'lambda_l2': 2.2347203782980047}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  65%|######5   | 13/20 [00:08<00:04,  1.56it/s]\u001b[32m[I 2023-01-26 14:55:30,345]\u001b[0m Trial 55 finished with value: 0.8756497698486815 and parameters: {'lambda_l1': 1.9992280500836423e-05, 'lambda_l2': 0.3062083934184353}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  70%|#######   | 14/20 [00:09<00:03,  1.52it/s]\u001b[32m[I 2023-01-26 14:55:31,043]\u001b[0m Trial 56 finished with value: 0.87518188965433 and parameters: {'lambda_l1': 9.176119765330011e-06, 'lambda_l2': 8.098988578433548}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  75%|#######5  | 15/20 [00:09<00:03,  1.54it/s]\u001b[32m[I 2023-01-26 14:55:31,672]\u001b[0m Trial 57 finished with value: 0.8758971499010979 and parameters: {'lambda_l1': 0.0007281844922452537, 'lambda_l2': 0.0009842660274883754}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  80%|########  | 16/20 [00:10<00:02,  1.53it/s]\u001b[32m[I 2023-01-26 14:55:32,335]\u001b[0m Trial 58 finished with value: 0.8752445592473282 and parameters: {'lambda_l1': 1.8573509194014463e-06, 'lambda_l2': 0.04656785918469191}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  85%|########5 | 17/20 [00:10<00:01,  1.55it/s]\u001b[32m[I 2023-01-26 14:55:32,966]\u001b[0m Trial 59 finished with value: 0.8758971497758864 and parameters: {'lambda_l1': 0.0007595985653602018, 'lambda_l2': 0.0001576613903509005}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  90%|######### | 18/20 [00:11<00:01,  1.58it/s]\u001b[32m[I 2023-01-26 14:55:33,564]\u001b[0m Trial 60 finished with value: 0.8756282362321773 and parameters: {'lambda_l1': 0.5472907919709215, 'lambda_l2': 0.18584495699142}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381:  95%|#########5| 19/20 [00:12<00:00,  1.55it/s]\u001b[32m[I 2023-01-26 14:55:34,241]\u001b[0m Trial 61 finished with value: 0.8754784703750452 and parameters: {'lambda_l1': 0.003978788455686139, 'lambda_l2': 0.004532789665120734}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381: 100%|##########| 20/20 [00:12<00:00,  1.58it/s]\u001b[32m[I 2023-01-26 14:55:34,847]\u001b[0m Trial 62 finished with value: 0.8757838880676809 and parameters: {'lambda_l1': 0.1556752536110443, 'lambda_l2': 1.175196924588097e-05}. Best is trial 45 with value: 0.8763812355245925.\u001b[0m\n",
      "regularization_factors, val_score: 0.876381: 100%|##########| 20/20 [00:12<00:00,  1.56it/s]\n",
      "min_data_in_leaf, val_score: 0.876381:  20%|##        | 1/5 [00:00<00:02,  1.51it/s]\u001b[32m[I 2023-01-26 14:55:35,510]\u001b[0m Trial 63 finished with value: 0.8755310629137194 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.8755310629137194.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.876381:  40%|####      | 2/5 [00:01<00:02,  1.47it/s]\u001b[32m[I 2023-01-26 14:55:36,204]\u001b[0m Trial 64 finished with value: 0.8739457622510397 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.8755310629137194.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.876381:  60%|######    | 3/5 [00:01<00:01,  1.51it/s]\u001b[32m[I 2023-01-26 14:55:36,843]\u001b[0m Trial 65 finished with value: 0.8746319003168578 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.8755310629137194.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.876381:  80%|########  | 4/5 [00:02<00:00,  1.49it/s]\u001b[32m[I 2023-01-26 14:55:37,524]\u001b[0m Trial 66 finished with value: 0.8758996480949512 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.8758996480949512.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.876381: 100%|##########| 5/5 [00:03<00:00,  1.49it/s]\u001b[32m[I 2023-01-26 14:55:38,194]\u001b[0m Trial 67 finished with value: 0.8754490609784151 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.8758996480949512.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.876381: 100%|##########| 5/5 [00:03<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import optuna.integration.lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# LightGBM用のデータセットに変換\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "# ハイパーパラメータサーチ&モデル構築\n",
    "params = {'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'random_seed':1234,\n",
    "        'n_jobs':-1,\n",
    "        'force_row_wise':True,\n",
    "        'verbose': -1 # これを指定しないと`No further splits with positive gain, best gain: -inf`というWarningが表示される\n",
    "        } \n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=1234)\n",
    "# クロスバリデーションによるハイパーパラメータの探索 3fold\n",
    "tuner = lgb.LightGBMTunerCV(\n",
    "                        params, lgb_train,\n",
    "                        callbacks=[\n",
    "                                lgb.early_stopping(stopping_rounds=100,verbose=False),\n",
    "                                lgb.log_evaluation(False)\n",
    "                                ],\n",
    "                        folds=kf\n",
    "                        )\n",
    "# ハイパーパラメータ探索の実行\n",
    "tuner.run()\n",
    "# サーチしたパラメータの表示\n",
    "best_params = tuner.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\ttraining's auc: 0.896335\tvalid_1's auc: 0.871105\n"
     ]
    }
   ],
   "source": [
    "#パラメータをもとに再学習\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_val = lgb.Dataset(X_val,y_val)\n",
    "\n",
    "model = lgbn.train(best_params, lgb_train,\n",
    "                valid_sets=[lgb_train, lgb_val],\n",
    "                callbacks=[\n",
    "                        lgb.early_stopping(100),\n",
    "                        lgb.log_evaluation(False),\n",
    "                        ],\n",
    "                num_boost_round =1000\n",
    "                )\n",
    "\n",
    "val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def binary(pred_y):\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i] > 0.5:\n",
    "            pred_y[i] = int(1)\n",
    "        else:\n",
    "            pred_y[i] = int(0)\n",
    "    return pred_y\n",
    "\n",
    "val_pred = binary(val_pred)\n",
    "accuracy_score(y_val,val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(X_test)\n",
    "test_data['y'] = pred_y\n",
    "test_data['y'] = test_data['y'].apply(int)\n",
    "test_data['y'].to_csv('data/submit.csv',header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=[0.1, 1, 10], cv=4, random_state=1234)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "clf = LogisticRegressionCV(cv=4,Cs=[0.1,1,10],random_state=1234,)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713125"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def param():\n",
    "#     ret = {\n",
    "#         'C':[1, 10, 100],\n",
    "#         'kernel':['rbf', 'linear', 'poly'],\n",
    "#         #'degree':np.arange(1, 6, 1),\n",
    "#         #'gamma':np.linspace(0.01, 1.0, 50)\n",
    "#         }\n",
    "#     return ret\n",
    "\n",
    "# clf = GridSearchCV(\n",
    "#     SVC(), # 識別器\n",
    "#     param(), # 最適化したいパラメータセット \n",
    "#     cv=4, # 交差検定の回数\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1) # モデルの評価関数の指定\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "clf = SVC(C=1,kernel='rbf')\n",
    "clf.fit(X_train,y_train)\n",
    "pred = clf.predict(X_val)\n",
    "print(accuracy_score(y_val,pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = clf.best_estimator_\n",
    "pred = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', 1e-5, 1),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-5, 1 ),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'sigmoid'])\n",
    "        }\n",
    "    \n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    accuracy_test = accuracy_score(y_val,pred)\n",
    "    \n",
    "    return 1.0 - accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:06) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "670c604040d66b29972be6a0c76e08c75b836d1021775c9e646b5f6bc58d26fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
